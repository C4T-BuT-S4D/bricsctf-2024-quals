// @generated
// This file is @generated by prost-build.
/// Represents the (discrete) probability distribution of a random variable with
/// natural (i.e. integer greater of equal to zero) support: counts\[i\]/sum is the
/// probability of observation of i.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct IntegerDistributionDouble {
    /// \[required\]
    #[prost(double, repeated, tag="1")]
    pub counts: ::prost::alloc::vec::Vec<f64>,
    /// \[required\]
    #[prost(double, optional, tag="2")]
    pub sum: ::core::option::Option<f64>,
}
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct IntegerDistributionFloat {
    /// \[required\]
    #[prost(float, repeated, tag="1")]
    pub counts: ::prost::alloc::vec::Vec<f32>,
    /// \[required\]
    #[prost(float, optional, tag="2")]
    pub sum: ::core::option::Option<f32>,
}
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct IntegerDistributionInt64 {
    /// \[required\]
    #[prost(int64, repeated, tag="1")]
    pub counts: ::prost::alloc::vec::Vec<i64>,
    /// \[required\]
    #[prost(int64, optional, tag="2")]
    pub sum: ::core::option::Option<i64>,
}
/// Describe a 1d normal distribution.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct NormalDistributionDouble {
    /// \[required\]
    #[prost(double, optional, tag="1")]
    pub sum: ::core::option::Option<f64>,
    /// \[required\]
    #[prost(double, optional, tag="2")]
    pub sum_squares: ::core::option::Option<f64>,
    /// \[required\]
    #[prost(double, optional, tag="3")]
    pub count: ::core::option::Option<f64>,
}
/// Confusion matrix between two integer distributions.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct IntegersConfusionMatrixDouble {
    /// Contains nrow x ncol elements. Low column indexed i.e. the second element
    /// is counts\[1,0\].
    /// \[required\]
    #[prost(double, repeated, tag="1")]
    pub counts: ::prost::alloc::vec::Vec<f64>,
    /// \[required\]
    #[prost(double, optional, tag="2")]
    pub sum: ::core::option::Option<f64>,
    /// \[required\]
    #[prost(int32, optional, tag="3")]
    pub nrow: ::core::option::Option<i32>,
    /// \[required\]
    #[prost(int32, optional, tag="4")]
    pub ncol: ::core::option::Option<i32>,
}
/// Header attached to an exported sharded multi-bitmap.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct ShardedMultiBitmapHeader {
    /// These fields are the same as the fields defined in "ShardedMultiBitmap".
    #[prost(int32, optional, tag="1")]
    pub bits_by_elements: ::core::option::Option<i32>,
    #[prost(uint64, optional, tag="2")]
    pub num_elements: ::core::option::Option<u64>,
    #[prost(uint64, optional, tag="3")]
    pub max_num_element_in_shard: ::core::option::Option<u64>,
    #[prost(uint64, optional, tag="4")]
    pub num_shards: ::core::option::Option<u64>,
}
/// Configuration for the generation of training and testing folds.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FoldGenerator {
    /// Seed used to control the fold generation. A same seed is guarantied to
    /// generate same folds for a given dataset.
    #[prost(int64, optional, tag="3", default="1234")]
    pub seed: ::core::option::Option<i64>,
    #[prost(oneof="fold_generator::Generator", tags="1, 2, 4, 5, 6")]
    pub generator: ::core::option::Option<fold_generator::Generator>,
}
/// Nested message and enum types in `FoldGenerator`.
pub mod fold_generator {
    // Next ID: 6

    /// Specify the "fold group" of each example. If specified, all the examples of
    /// the same group will appear in the same fold. In other words, each group
    /// will either be entirely used for training or for testing.
    ///
    /// There should be at least as much groups as there are folds.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct FoldGroup {
        /// Name of a categorical attribute that defines the "group" membership of
        /// each example.
        ///
        /// Next ID: 2
        #[prost(string, optional, tag="1")]
        pub group_attribute: ::core::option::Option<::prost::alloc::string::String>,
    }
    /// Split the dataset in two folds. The first part will be used for training.
    /// The second part will be used for evaluation. This method is commonly called
    /// "Train and test" evaluation.
    ///
    /// This method is fast (only one model is trained) but the results are noisy
    /// (both with training noise and testing noise).
    #[derive(Clone, Copy, PartialEq, ::prost::Message)]
    pub struct TrainTest {
        /// Ratio of the dataset used for testing. The remaining examples are used
        /// for training.
        ///
        /// Next ID: 2
        #[prost(float, optional, tag="1", default="0.33")]
        pub test_ratio: ::core::option::Option<f32>,
    }
    /// Split the dataset into n folds (n=10 by default). Then, for each subset of
    /// n-1 folds, train a model and evaluate it on the remaining folds. This
    /// methods is called "cross-validation".
    ///
    /// Cross-validation is more expensive (n models need to be trained) than
    /// "train and test" but the results are more precise.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct CrossValidation {
        /// If num_folds=0, a leave-one-out cross-validation is executed
        /// (i.e. "num_folds" is set to the number of examples in the dataset).
        #[prost(int32, optional, tag="1", default="10")]
        pub num_folds: ::core::option::Option<i32>,
        /// "fold_group_attribute" an attribute name that defines the "group"
        /// appurtenance of each example. If "fold_group_attribute" is specified, all
        /// the examples of the same group will appear in the same fold. In other
        /// words, each group will either be entirely used for training or for
        /// testing.
        ///
        /// Next ID: 3
        #[prost(message, optional, tag="2")]
        pub fold_group: ::core::option::Option<FoldGroup>,
    }
    /// Evaluate the candidate model on a separate dataset. The entire dataset
    /// specified in "TrainEvaluateCompareOptions" will be used for training. The
    /// entire dataset specified in "TestOnOtherDataset" will be used for testing.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct TestOnOtherDataset {
        /// Path (\[type\]:[path]) to the test dataset.
        #[prost(string, optional, tag="1")]
        pub dataset_path: ::core::option::Option<::prost::alloc::string::String>,
    }
    /// Does not train the model and evaluate on the entire dataset. This solution
    /// only make sense when the candidate method are all defined as pre-computed
    /// predictions or pre-computed models.
    #[derive(Clone, Copy, PartialEq, ::prost::Message)]
    pub struct NoTraining {
    }
    /// Cross-validation of folds computed externally.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct PrecomputedCrossValidation {
        /// Path (\[type\]:[path]) to a dataset containing numerical column called
        /// "fold_idx". "fold_idx\[i\]" in an integer in [0, num_folds) defining the
        /// folds of the i-th example.
        #[prost(string, optional, tag="1")]
        pub fold_path: ::core::option::Option<::prost::alloc::string::String>,
    }
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Generator {
        #[prost(message, tag="1")]
        TrainTest(TrainTest),
        #[prost(message, tag="2")]
        CrossValidation(CrossValidation),
        #[prost(message, tag="4")]
        TestOnOtherDataset(TestOnOtherDataset),
        #[prost(message, tag="5")]
        NoTraining(NoTraining),
        #[prost(message, tag="6")]
        PrecomputedCrossValidation(PrecomputedCrossValidation),
    }
}
/// Message for the metrics required to compute a partial dependence plot for
/// multiple features or sets of features.
///
/// This message is also used to store Conditional Expectancy Plots.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PartialDependencePlotSet {
    #[prost(message, repeated, tag="1")]
    pub pdps: ::prost::alloc::vec::Vec<partial_dependence_plot_set::PartialDependencePlot>,
}
/// Nested message and enum types in `PartialDependencePlotSet`.
pub mod partial_dependence_plot_set {
    /// Message for metrics required to compute a partial dependence plot for ONE
    /// feature or ONE set of features.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct PartialDependencePlot {
        #[prost(double, optional, tag="1")]
        pub num_observations: ::core::option::Option<f64>,
        #[prost(message, repeated, tag="3")]
        pub pdp_bins: ::prost::alloc::vec::Vec<partial_dependence_plot::Bin>,
        #[prost(message, repeated, tag="4")]
        pub attribute_info: ::prost::alloc::vec::Vec<partial_dependence_plot::AttributeInfo>,
    }
    /// Nested message and enum types in `PartialDependencePlot`.
    pub mod partial_dependence_plot {
        /// Represents the "sum" of a set of labels, either predicted by the model,
        /// or the ground truth.
        #[derive(Clone, PartialEq, ::prost::Message)]
        pub struct LabelAccumulator {
            #[prost(oneof="label_accumulator::PredictionValue", tags="1, 2, 3, 4")]
            pub prediction_value: ::core::option::Option<label_accumulator::PredictionValue>,
        }
        /// Nested message and enum types in `LabelAccumulator`.
        pub mod label_accumulator {
            #[derive(Clone, PartialEq, ::prost::Oneof)]
            pub enum PredictionValue {
                #[prost(message, tag="1")]
                ClassificationClassDistribution(super::super::super::IntegerDistributionFloat),
                /// sum_of_regression_predictions should be normalized with
                /// num_observations to obtain the mean prediction.
                #[prost(double, tag="2")]
                SumOfRegressionPredictions(f64),
                /// sum_of_ranking_predictions should be normalized with
                /// num_observations to obtain the mean prediction.
                #[prost(double, tag="3")]
                SumOfRankingPredictions(f64),
                /// sum_of_anomaly_detection_predictions should be normalized with
                /// num_observations to obtain the mean prediction.
                #[prost(double, tag="4")]
                SumOfAnomalyDetectionPredictions(f64),
            }
        }
        /// Represent the accumulation of evaluation metrics.
        #[derive(Clone, Copy, PartialEq, ::prost::Message)]
        pub struct EvaluationAccumulator {
            #[prost(oneof="evaluation_accumulator::PredictionValue", tags="1, 2")]
            pub prediction_value: ::core::option::Option<evaluation_accumulator::PredictionValue>,
        }
        /// Nested message and enum types in `EvaluationAccumulator`.
        pub mod evaluation_accumulator {
            #[derive(Clone, Copy, PartialEq, ::prost::Oneof)]
            pub enum PredictionValue {
                /// For regression.
                #[prost(double, tag="1")]
                SumSquaredError(f64),
                /// For classification.
                #[prost(double, tag="2")]
                NumCorrectPredictions(f64),
            }
        }
        /// Represents the metrics for a feature OR set of features at a particular
        /// value (Represented by attribute_values).
        #[derive(Clone, PartialEq, ::prost::Message)]
        pub struct Bin {
            #[prost(message, optional, tag="1")]
            pub prediction: ::core::option::Option<LabelAccumulator>,
            #[prost(message, optional, tag="2")]
            pub ground_truth: ::core::option::Option<LabelAccumulator>,
            #[prost(message, optional, tag="4")]
            pub evaluation: ::core::option::Option<EvaluationAccumulator>,
            /// The values used to represent the center of this bin.
            /// In case of a categorical feature, this stores the exact categorical
            /// value. In case of a numerical feature, this stores a value:
            /// (max_value - min_value)*(bin_number + 0.5)/num_bins + min_value.
            #[prost(message, repeated, tag="3")]
            pub center_input_feature_values: ::prost::alloc::vec::Vec<super::super::super::dataset::example::Attribute>,
        }
        #[derive(Clone, PartialEq, ::prost::Message)]
        pub struct AttributeInfo {
            /// If this PartialDependencePlot represents a set of 3 features,
            /// attribute_info.num_bins represents the number of bins in each of these
            /// feature spaces. Further, \product_i
            /// attribute_info\[i\].num_bins_per_input_feature = pdp_bins.size().
            #[prost(int32, optional, tag="1")]
            pub num_bins_per_input_feature: ::core::option::Option<i32>,
            #[prost(int32, optional, tag="2")]
            pub attribute_idx: ::core::option::Option<i32>,
            /// Distribution of the attribute for each of the bins.
            #[prost(double, repeated, packed="false", tag="3")]
            pub num_observations_per_bins: ::prost::alloc::vec::Vec<f64>,
            /// Boundaries of the bins for numerical attributes.
            #[prost(float, repeated, packed="false", tag="4")]
            pub numerical_boundaries: ::prost::alloc::vec::Vec<f32>,
            /// How to scale the axis when plotting this attribute. Only used for
            /// numerical attributes.
            #[prost(enumeration="attribute_info::Scale", optional, tag="5", default="Uniform")]
            pub scale: ::core::option::Option<i32>,
        }
        /// Nested message and enum types in `AttributeInfo`.
        pub mod attribute_info {
            #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
            #[repr(i32)]
            pub enum Scale {
                Uniform = 0,
                Log = 1,
            }
            impl Scale {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        Scale::Uniform => "UNIFORM",
                        Scale::Log => "LOG",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "UNIFORM" => Some(Self::Uniform),
                        "LOG" => Some(Self::Log),
                        _ => None,
                    }
                }
            }
        }
    }
}
// @@protoc_insertion_point(module)
